\documentclass[a4paper]{article}

\usepackage{amssymb,amsmath}

\author{Edoardo Pasca}

\title{Iterative Sample Statistic}
\date{\today}

\newcommand{\avg}{\bar{v}}

\begin{document}
\maketitle
Some time ago I was sick with some fever. The only thing I could do was to lay in bed and measure my body temperature. The thermometer took so little time to measure that I tried again and again. Each time the temperature was different.

I thought to measure a few times and then to calculate the average, to get a more stable result.

Doing it without a piece of paper starts to be a bit difficult when you have to deal with more than 5 samples (at least for me). I started thinking that there must be a way to update the last calculated average with the next sample.

\section{Mean}
The average is defined as:
\begin{equation}
\langle v\rangle_N = \frac{1}{N} \sum_{i=1}^N v_i
\label{eq:avg_def}
\end{equation}

Adding one sample $v_{N+1}$, the next evaluation of the average is:
\begin{align}
\avg_{N+1}  & =  \frac{1}{N+1} \sum_{i=1}^{N+1} v_i \nonumber \\
 & =  \frac{1}{N+1} \left( \sum_{i=1}^{N} v_i + v_{N+1} \right) \nonumber\\
 & =  \frac{1}{N+1} \left( N \avg_{N} + v_{N+1} \right) \nonumber\\
 & =  \frac{N}{N+1} \avg_{N} + \frac{v_{N+1}}{N+1}
\label{eq:iterative-avg}
\end{align}


where $\avg_{N+1}$ is the average calculated with $N+1$ samples and $N$ is 
the number of samples. This formula says that we can calculate the next 
average by keeping in mind only 3 numbers: the previous average, the number
of samplings and the last sample. That's nice!

\section{Standard Deviation}
The variance is defined as the square of the standard deviation $\sigma$:
\begin{equation}
\sigma_N^2 = \frac{1}{N-1} \sum_{i=1}^N \left(v_i - \avg_N\right)^2
\label{eq:std_def}
\end{equation}

Again, adding the $N+1$-th sample the estimation of the variance can be
expressed as:

\begin{equation}
\sigma_{N+1}^2   =  \frac{1}{N-1} \sum_{i=1}^{N+1} \left(v_i -
\avg_{N+1}\right)^2
\end{equation}
we now use the eq. \ref{eq:std_def} to express $\avg_{N+1}$ in terms of
$\avg_N$

\begin{equation}
\sigma_{N+1}^2  = \frac{1}{N} \sum_{i=1}^{N+1} \left(v_i -
\left( \frac{N}{N+1} \avg_{N} + \frac{v_{N+1}}{N+1} \right)
 \right)^2 
 \label{eq:var-n+1}
 %& = \frac{1}{N-1}\left( \sum_{i=1}^{N} \left(v_i -
 %\frac{N}{N+1} \avg_{N} + \frac{v_{N+1}}{N+1} \right)^2  + 
 %\left(v_{N+1} -
 %\frac{N}{N+1} \avg_{N} + \frac{v_{N+1}}{N+1} \right)^2
 %\right) \nonumber
\end{equation}

Before going further, we better arrange the term in the sum with a nice trick:
\begin{align}
v_i - \left(\frac{N}{N+1} \avg_{N} + \frac{v_{N+1}}{N+1}\right)& =  \nonumber \\
& = v_i - \left( \avg_N - \avg_N + \frac{N}{N+1} \avg_{N}+
\frac{v_{N+1}}{N+1}\right) \nonumber \\
& = v_i - \avg_N - \left( - \avg_N + \frac{N}{N+1} \avg_{N}+
\frac{v_{N+1}}{N+1}\right) \nonumber \\
& = \left(v_i - \avg_N\right) - \left( \frac{N-(N+1)}{N+1} \avg_{N}+
\frac{v_{N+1}}{N+1}\right) \nonumber \\
& = \left(v_i - \avg_N\right) - \left(-\frac{1}{N+1} \avg_{N}+
\frac{v_{N+1}}{N+1}\right) 
\label{eq:trick}
\end{align}

The term in the sum is actually expressed by the sum of two terms, the first
depending on the various samplings, $v_i$ and the previous evaluation of the
average, $\avg_N$,
and the second term depending only on the previous evaluation of the average,
$\avg_N$, the number of samplings, $N$, and the last sample, $v_{N+1}$.

\begin{align}
a_i = & v_i - \avg_N \label{eq:a_i} \\
b_{N,\avg_N} = b = & \frac{v_{N+1}-\avg_{N}}{N+1} \label{eq:b}
\end{align}

Now we can express the variance, eq. \ref{eq:var-n+1}, with the help of 
these variables $a_i$ and b as,
\begin{align}
\sigma_{N+1}^2  = & \frac{1}{N} \left[\left(\sum_{i=1}^{N} \left(a_i -
b\right)^2 \right) 
 + \left(a_{N+1} - b\right)^2\right] \\
 = & \frac{1}{N} \left[\left(\sum_{i=1}^{N} \left(a_i^2 +
b^2 - 2a_ib\right) \right) 
 + \left(a_{N+1} - b\right)^2\right] \nonumber \\
 = & \frac{1}{N} \left[\left(\sum_{i=1}^{N} \left(a_i^2 +
b^2 \right) \right) 
+ \left(a_{N+1} - b\right)^2\right] = 
  \frac{1}{N} \left[\left(\sum_{i=1}^{N} a_i^2 \right) +
N b^2  
 + \left(a_{N+1} - b\right)^2\right] \nonumber \\
 = & \frac{1}{N} \left[(N-1)\sigma_N^2  +
N b^2  
 + \left(a_{N+1} - b\right)^2\right] \nonumber \\
 = & \frac{1}{N} \left[(N-1)\sigma_N^2  +
 \frac{N}{N+1} \left(v_{N+1} - \avg_N \right)^2
 \right] \nonumber \\
 \sigma_{N+1}^2 = & \frac{N-1}{N} \sigma_N^2  +
 \frac{1}{N+1} \left(v_{N+1} - \avg_N \right)^2
 \label{eq:iterative-var}
\end{align}

Eqs. (\ref{eq:iterative-avg}) and (\ref{eq:iterative-var}) allow to iterative
calculate the next estimation of average and variance using only the previous
estimation, the last sampling and the number of samples. 

\section{Higher order moments}
As last algebraic remark, 
\begin{align}
a_{N+1} - b = & (v_{N+1} - \avg_N) - \frac{1}{N+1} (v_{N+1} - \avg_N)
\nonumber \\
 = & \frac{N}{N+1} (v_{N+1} - \avg_N) \nonumber \\
 a_{N+1} - b= & N b
\end{align}
We can easily extend this treatment to higher standardized moments of the 
distribution of the population:

\begin{equation}
x_k = \frac{\sum_{i=1}^N \left(v_i - \avg_N\right)^k}{\sigma^k_N} =
\frac{M_{N,k}}{\sigma^k_N}
\end{equation}
where $k$ is the moment's order. It is now very easy to calculate the

\begin{align}
M_{N+1,k} = & \sum_i^{N+1} (v_i - \avg_{N+1})^k \nonumber \\
 = & \left[\sum_i^N (a_i - b)^k\right] + (a_{N+1} - b) ^k \nonumber \\
 = & \left[\sum_i^N (a_i - b)^k \right]+ (Nb)^k
 \label{eq:kth-moment}
\end{align}

\subsection{Skewness}
The skewness is a third order moment, $k=3$. 

\begin{align}
M_{N+1,3} = & \left[\sum_i^N (a_i - b)^3 \right]+ (Nb)^3 \nonumber \\
 = & \left[\sum_i^N (a_i^3 - b^3 +3a_ib^2 - 3a_i^2b) \right]+ (Nb)^3 \nonumber \\
 = & \left[\sum_i^N (a_i^3 - 3a_i^2b) \right] -Nb^3 + (Nb)^3 \nonumber \\
 = & \left[\sum_i^N (a_i^3 - 3a_i^2b) \right]+ Nb^3 (N^2-1)  \nonumber \\
 = & M_{N,3} - 3b \left[\sum_i^N a_i^2 \right]+ Nb^3 (N^2-1)  \nonumber \\
 = & M_{N,3} - 3 b (N-1)\sigma_N^2 + Nb^3 (N-1)(N+1)  \nonumber \\
\end{align}
\subsection{Kurtosis}
The kurtosis is a fourth order moment, $k=4$. 

\begin{align}
M_{N+1,4} = & \left[\sum_i^N (a_i - b)^4 \right]+ (Nb)^4 \nonumber \\
 = & \left[\sum_i^N (a_i^4 +b^4-4a_i^3+5a_i^2) \right]+ (Nb)^4 \nonumber \\
 = & \left[\sum_i^N (a_i^3 - 3a_i^2b) \right] -Nb^3 + (Nb)^4 \nonumber \\
 = & \left[\sum_i^N (a_i^3 - 3a_i^2b) \right]+ Nb^3 (N^2-1)  \nonumber \\
 = & M_{N,3} - 3b \left[\sum_i^N a_i^2 \right]+ Nb^3 (N^2-1)  \nonumber \\
 = & M_{N,3} - 3 b (N-1)\sigma_N^2 + Nb^3 (N-1)(N+1)  \nonumber \\
\end{align}
\end{document}
